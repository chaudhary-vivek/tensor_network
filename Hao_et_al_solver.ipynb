{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Solution: [tensor(1), tensor(0), tensor(0), tensor(0)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.linalg import svd\n",
    "\n",
    "def construct_hamiltonian(weights):\n",
    "    \"\"\"Constructs the Hamiltonian for an unconstrained binary optimization problem.\"\"\"\n",
    "    n = len(weights)\n",
    "    H = torch.zeros((2**n, 2**n))\n",
    "    \n",
    "    for i in range(2**n):\n",
    "        x = torch.tensor([(i >> j) & 1 for j in range(n)])\n",
    "        H[i, i] = torch.dot(weights, x.float())\n",
    "    \n",
    "    return H\n",
    "\n",
    "def postselection_projector(valid_solutions, n):\n",
    "    \"\"\"Constructs a projection operator that projects onto valid constraint-satisfying states.\"\"\"\n",
    "    P = torch.zeros((2**n, 2**n))\n",
    "    for sol in valid_solutions:\n",
    "        idx = int(\"\".join(map(str, sol)), 2)\n",
    "        P[idx, idx] = 1.0\n",
    "    return P\n",
    "\n",
    "def tensor_network_representation(valid_solutions, n):\n",
    "    \"\"\"Constructs a tensor network representation of valid solutions.\"\"\"\n",
    "    tensors = []\n",
    "    for i in range(n):\n",
    "        Ti = torch.zeros((2, 2))\n",
    "        for sol in valid_solutions:\n",
    "            Ti[sol[i], sol[i]] = 1\n",
    "        tensors.append(Ti)\n",
    "    return tensors\n",
    "\n",
    "def imaginary_time_evolution(H, psi_0, tau=1.0, steps=100):\n",
    "    \"\"\"Applies imaginary time evolution to find the ground state.\"\"\"\n",
    "    psi = psi_0.clone()\n",
    "    for _ in range(steps):\n",
    "        psi = torch.mm(torch.matrix_exp(-tau * H), psi)\n",
    "        psi /= torch.norm(psi)\n",
    "    return psi\n",
    "\n",
    "def extract_optimal_solution(psi, n):\n",
    "    \"\"\"Finds the optimal binary solution by measuring the expectation of Z operator.\"\"\"\n",
    "    best_idx = torch.argmax(torch.abs(psi))\n",
    "    best_solution = [(best_idx >> i) & 1 for i in range(n)]\n",
    "    return best_solution\n",
    "\n",
    "# Example usage\n",
    "n = 4  # Number of variables\n",
    "weights = torch.tensor([-1.2, 2.5, -3.0, 0.5])\n",
    "valid_solutions = [[0, 0, 0, 1], [0, 1, 1, 0], [1, 0, 1, 1]]\n",
    "\n",
    "H = construct_hamiltonian(weights)\n",
    "P = postselection_projector(valid_solutions, n)\n",
    "H_proj = torch.mm(P, torch.mm(H, P))\n",
    "\n",
    "psi_0 = torch.ones((2**n, 1)) / np.sqrt(2**n)\n",
    "psi_g = imaginary_time_evolution(H_proj, psi_0)\n",
    "\n",
    "optimal_solution = extract_optimal_solution(psi_g, n)\n",
    "print(\"Optimal Solution:\", optimal_solution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal solution: [0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tt/3h_jlt8571z664b95jr80v_40000gn/T/ipykernel_12767/2439081650.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mask = torch.tensor(c, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Step 1: Define the problem (Binary optimization)\n",
    "def generate_hamiltonian(weights):\n",
    "    \"\"\"Constructs the Hamiltonian matrix H for the optimization problem.\"\"\"\n",
    "    n = len(weights)\n",
    "    dim = 2**n  # Size of the Hamiltonian matrix\n",
    "    H = torch.zeros((dim, dim), dtype=torch.float32)\n",
    "    for i in range(n):\n",
    "        Z = torch.tensor([[1, 0], [0, -1]], dtype=torch.float32)\n",
    "        I = torch.eye(2, dtype=torch.float32)\n",
    "        ops = [I] * n\n",
    "        ops[i] = Z  # Apply Z at the i-th position\n",
    "        term = ops[0]\n",
    "        for op in ops[1:]:\n",
    "            term = torch.kron(term, op)\n",
    "        H += weights[i] * term\n",
    "    return H\n",
    "\n",
    "# Step 2: Define tensor network constraints (simple projector)\n",
    "def apply_constraints(state, constraints):\n",
    "    \"\"\"Projects state onto feasible constraint space.\"\"\"\n",
    "    for c in constraints:\n",
    "        mask = torch.tensor(c, dtype=torch.float32)\n",
    "        state *= mask\n",
    "    return state / state.norm()  # Normalize\n",
    "\n",
    "# Step 3: Imaginary Time Evolution (Gradient Descent-like minimization)\n",
    "def imaginary_time_evolution(state, H, tau=0.1, steps=100):\n",
    "    \"\"\"Performs imaginary time evolution to find the ground state.\"\"\"\n",
    "    for _ in range(steps):\n",
    "        state = torch.matrix_exp(-tau * H) @ state  # Use @ for matrix-vector multiplication\n",
    "        state /= state.norm()\n",
    "    return state\n",
    "\n",
    "# Example: Optimize a simple problem\n",
    "n = 3  # Number of variables\n",
    "weights = [-1, -2, -3]  # Example cost function (minimize sum of x)\n",
    "H = generate_hamiltonian(weights)\n",
    "initial_state = torch.ones((2**n, 1), dtype=torch.float32) / np.sqrt(2**n)  # Equal superposition\n",
    "constraints = [torch.randint(0, 2, (2**n, 1))]  # Random binary constraints\n",
    "\n",
    "# Apply constraints and optimize\n",
    "state = apply_constraints(initial_state, constraints)\n",
    "optimal_state = imaginary_time_evolution(state, H)\n",
    "\n",
    "# Extract best solution\n",
    "best_solution = (optimal_state < 0).int().squeeze()\n",
    "print(\"Optimal solution:\", best_solution.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[0, 1, 0, 1, 1],\n",
    "         [1, 0, 0, 1, 0],\n",
    "         [0, 0, 0, 0, 1],\n",
    "         [1, 1, 0, 0, 0],\n",
    "         [1, 0, 1, 0, 0]])\n",
    "\n",
    "K = np.array([[1,0,0], \n",
    "                     [0,1,0],\n",
    "                     [1,0,0], \n",
    "                     [0,0,1], \n",
    "                     [0,1,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def encode(A, K, lambda_factor=None):\n",
    "    n, k = K.shape\n",
    "    if lambda_factor is None:\n",
    "        lambda_factor = k + 1  # Ensure uniqueness\n",
    "\n",
    "    # Find the max-index column of 1s for each row in K (rightmost 1)\n",
    "    max_indices = np.where(K == 1)[1].reshape(n, -1).max(axis=1)\n",
    "\n",
    "    # Create encoded matrix\n",
    "    encoded_A = A.copy().astype(float)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):  # Only fill upper triangular, symmetric\n",
    "            if A[i, j] == 1 and max_indices[i] == max_indices[j]:  # Same max-column\n",
    "                encoded_A[i, j] += lambda_factor * (max_indices[i] + 1)\n",
    "    \n",
    "    return np.maximum(encoded_A, encoded_A.T)  # Ensure symmetry\n",
    "\n",
    "def decode(encoded_A, A, k, lambda_factor=None):\n",
    "    if lambda_factor is None:\n",
    "        lambda_factor = k + 1  # Same as in encoding\n",
    "\n",
    "    n = A.shape[0]\n",
    "    K_reconstructed = np.zeros((n, k), dtype=int)\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if A[i, j] == 1:\n",
    "                encoded_value = encoded_A[i, j]\n",
    "                max_index = int((encoded_value // lambda_factor) - 1)\n",
    "                if max_index >= 0 and max_index < k:\n",
    "                    K_reconstructed[i, max_index] = 1\n",
    "                    K_reconstructed[j, max_index] = 1\n",
    "\n",
    "    return K_reconstructed\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
